{"version":3,"sources":["webpack:///./src/glslang.ts","webpack:///./src/examples/videoUploading.ts"],"names":["glslang","undefined","glslangModule","import","default","title","description","init","canvas","video","document","createElement","loop","autoplay","muted","src","play","adapter","navigator","gpu","requestAdapter","device","requestDevice","context","getContext","rectVerts","Float32Array","verticesBuffer","createBuffer","size","byteLength","usage","GPUBufferUsage","VERTEX","mappedAtCreation","getMappedRange","set","unmap","swapChain","configureSwapChain","format","pipeline","createRenderPipeline","vertexStage","module","createShaderModule","code","glslShaders","vertex","transform","glsl","compileGLSL","entryPoint","fragmentStage","fragment","primitiveTopology","vertexState","vertexBuffers","arrayStride","attributes","shaderLocation","offset","colorStates","sampler","createSampler","magFilter","minFilter","videoTexture","createTexture","width","videoWidth","height","videoHeight","depth","GPUTextureUsage","COPY_DST","SAMPLED","uniformBindGroup","createBindGroup","layout","getBindGroupLayout","entries","binding","resource","createView","createImageBitmap","then","videoFrame","defaultQueue","copyImageBitmapToTexture","imageBitmap","origin","x","y","texture","commandEncoder","createCommandEncoder","renderPassDescriptor","colorAttachments","attachment","getCurrentTexture","loadValue","r","g","b","a","passEncoder","beginRenderPass","setPipeline","setVertexBuffer","setBindGroup","draw","endPass","submit","finish","wgslShaders"],"mappings":"mYAAA,IAAIA,OAAUC,EACC,e,yCACb,QAAgBA,IAAZD,EAAuB,OAAOA,EAElC,MAAME,QAAsBC,OAAiC,sEAE7D,OADAH,QAAgBE,EAAcE,UACvBJ,O,uiBCJF,MAAMK,EAAQ,gBACRC,EAAc,0DAEpB,SAAeC,EAAKC,G,yCAEzB,MAAMC,EAAQC,SAASC,cAAc,SACrCF,EAAMG,MAAO,EACbH,EAAMI,UAAW,EACjBJ,EAAMK,OAAQ,EACdL,EAAMM,IAAM,+BACNN,EAAMO,OAEZ,MAAMC,QAAgBC,UAAUC,IAAIC,iBAC9BC,QAAeJ,EAAQK,gBACvBtB,QAAgB,cAChBuB,EAAUf,EAAOgB,WAAW,cAI5BC,EAAY,IAAIC,aAAa,CACjC,EAAM,EAAK,EAAK,EAAK,EACrB,GAAM,EAAK,EAAK,EAAK,GACpB,GAAM,EAAK,EAAK,EAAK,EACtB,EAAM,EAAK,EAAK,EAAK,GACpB,GAAM,EAAK,EAAK,EAAK,GACrB,EAAM,EAAK,EAAK,EAAK,IAGlBC,EAAiBN,EAAOO,aAAa,CACzCC,KAAMJ,EAAUK,WAChBC,MAAOC,eAAeC,OACtBC,kBAAkB,IAEpB,IAAIR,aAAaC,EAAeQ,kBAAkBC,IAAIX,GACtDE,EAAeU,QAEf,MAAMC,EAAYf,EAAQgB,mBAAmB,CAC3ClB,SACAmB,OArBsB,eAwBlBC,EAAWpB,EAAOqB,qBAAqB,CAC3CC,YAAa,CACXC,OAAQvB,EAAOwB,mBAAmB,CAChCC,KAAMC,EAAYC,OAClBC,UAAYC,GAASlD,EAAQmD,YAAYD,EAAM,YAEjDE,WAAY,QAEdC,cAAe,CACbT,OAAQvB,EAAOwB,mBAAmB,CAChCC,KAAMC,EAAYO,SAClBL,UAAYC,GAASlD,EAAQmD,YAAYD,EAAM,cAEjDE,WAAY,QAGdG,kBAAmB,gBACnBC,YAAa,CACXC,cAAe,CAAC,CACdC,YAAa,GACbC,WAAY,CAAC,CAEXC,eAAgB,EAChBC,OAAQ,EACRrB,OAAQ,UACP,CAEDoB,eAAgB,EAChBC,OAAQ,GACRrB,OAAQ,cAKdsB,YAAa,CAAC,CACZtB,OA3DoB,iBA+DlBuB,EAAU1C,EAAO2C,cAAc,CACnCC,UAAW,SACXC,UAAW,WAGPC,EAAe9C,EAAO+C,cAAc,CACxCvC,KAAM,CACJwC,MAAO5D,EAAM6D,WACbC,OAAQ9D,EAAM+D,YACdC,MAAO,GAETjC,OAAQ,aACRT,MAAO2C,gBAAgBC,SAAWD,gBAAgBE,UAG9CC,EAAmBxD,EAAOyD,gBAAgB,CAC9CC,OAAQtC,EAASuC,mBAAmB,GACpCC,QAAS,CAAC,CACRC,QAAS,EACTC,SAAUpB,GACT,CACDmB,QAAS,EACTC,SAAUhB,EAAaiB,iBAI3B,OAAO,WACLC,kBAAkB5E,GAAO6E,KAAKC,IAC5BlE,EAAOmE,aAAaC,yBAClB,CAACC,YAAYH,EAAYI,OAAQ,CAACC,EAAE,EAAGC,EAAG,IAC1C,CAACC,QAAS3B,GACV,CAACE,MAAO5D,EAAM6D,WAAYC,OAAO9D,EAAM+D,YAAaC,MAAO,IAG7D,MAAMsB,EAAiB1E,EAAO2E,uBAGxBC,EAAuB,CAC3BC,iBAAkB,CAAC,CACjBC,WAJgB7D,EAAU8D,oBAAoBhB,aAK9CiB,UAAW,CAAEC,EAAG,EAAKC,EAAG,EAAKC,EAAG,EAAKC,EAAG,MAItCC,EAAcX,EAAeY,gBAAgBV,GACnDS,EAAYE,YAAYnE,GACxBiE,EAAYG,gBAAgB,EAAGlF,GAC/B+E,EAAYI,aAAa,EAAGjC,GAC5B6B,EAAYK,KAAK,EAAG,EAAG,EAAG,GAC1BL,EAAYM,UACZ3F,EAAOmE,aAAayB,OAAO,CAAClB,EAAemB,iBAK1C,MAAMnE,EAAc,CACzBC,OAAQ,8MAYRM,SAAU,2SAaC6D,EAAc,CACzBnE,OAAQ,sRAaRM,SAAU","file":"videoUploading-c6cfbc.js","sourcesContent":["let glslang = undefined;\nexport default async function() {\n  if (glslang !== undefined) return glslang;\n  // @ts-ignore\n  const glslangModule = await import(/* webpackIgnore: true */ 'https://unpkg.com/@webgpu/glslang@0.0.15/dist/web-devel/glslang.js');\n  glslang = await glslangModule.default();\n  return glslang;\n}\n","import glslangModule from '../glslang';\n\nexport const title = 'Video Texture';\nexport const description = 'This example shows how to upload video frame to WebGPU.';\n\nexport async function init(canvas: HTMLCanvasElement) {\n  // Set video element\n  const video = document.createElement('video');\n  video.loop = true;\n  video.autoplay = true;\n  video.muted = true;\n  video.src = 'assets/video/pano.webm';\n  await video.play();\n\n  const adapter = await navigator.gpu.requestAdapter();\n  const device = await adapter.requestDevice();\n  const glslang = await glslangModule();\n  const context = canvas.getContext('gpupresent');\n\n  const swapChainFormat = \"bgra8unorm\";\n\n  const rectVerts = new Float32Array([\n    1.0,  1.0, 0.0, 1.0, 0.0,\n    1.0, -1.0, 0.0, 1.0, 1.0,\n    -1.0, -1.0, 0.0, 0.0, 1.0,\n    1.0,  1.0, 0.0, 1.0, 0.0,\n    -1.0, -1.0, 0.0, 0.0, 1.0,\n    -1.0,  1.0, 0.0, 0.0, 0.0,\n  ]);\n\n  const verticesBuffer = device.createBuffer({\n    size: rectVerts.byteLength,\n    usage: GPUBufferUsage.VERTEX,\n    mappedAtCreation: true,\n  });\n  new Float32Array(verticesBuffer.getMappedRange()).set(rectVerts);\n  verticesBuffer.unmap();\n\n  const swapChain = context.configureSwapChain({\n    device,\n    format: swapChainFormat,\n  });\n\n  const pipeline = device.createRenderPipeline({\n    vertexStage: {\n      module: device.createShaderModule({\n        code: glslShaders.vertex,\n        transform: (glsl) => glslang.compileGLSL(glsl, \"vertex\"),\n      }),\n      entryPoint: \"main\"\n    },\n    fragmentStage: {\n      module: device.createShaderModule({\n        code: glslShaders.fragment,\n        transform: (glsl) => glslang.compileGLSL(glsl, \"fragment\"),\n      }),\n      entryPoint: \"main\"\n    },\n\n    primitiveTopology: \"triangle-list\",\n    vertexState: {\n      vertexBuffers: [{\n        arrayStride: 20,\n        attributes: [{\n          // position\n          shaderLocation: 0,\n          offset: 0,\n          format: \"float3\"\n        }, {\n          // uv\n          shaderLocation: 1,\n          offset: 12,\n          format: \"float2\"\n        }]\n      }],\n    },\n\n    colorStates: [{\n      format: swapChainFormat,\n    }],\n  });\n\n  const sampler = device.createSampler({\n    magFilter: \"linear\",\n    minFilter: \"linear\",\n  });\n\n  const videoTexture = device.createTexture({\n    size: {\n      width: video.videoWidth,\n      height: video.videoHeight,\n      depth: 1,\n    },\n    format: 'rgba8unorm',\n    usage: GPUTextureUsage.COPY_DST | GPUTextureUsage.SAMPLED,\n  });\n\n  const uniformBindGroup = device.createBindGroup({\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [{\n      binding: 0,\n      resource: sampler,\n    }, {\n      binding: 1,\n      resource: videoTexture.createView(),\n    }],\n  });\n\n  return function frame() {\n    createImageBitmap(video).then(videoFrame => {\n      device.defaultQueue.copyImageBitmapToTexture(\n        {imageBitmap:videoFrame, origin: {x:0, y: 0} },\n        {texture: videoTexture},\n        {width: video.videoWidth, height:video.videoHeight, depth: 1}\n      );\n\n      const commandEncoder = device.createCommandEncoder();\n      const textureView = swapChain.getCurrentTexture().createView();\n\n      const renderPassDescriptor = {\n        colorAttachments: [{\n          attachment: textureView,\n          loadValue: { r: 0.0, g: 0.0, b: 0.0, a: 1.0 },\n        }],\n      };\n\n      const passEncoder = commandEncoder.beginRenderPass(renderPassDescriptor);\n      passEncoder.setPipeline(pipeline);\n      passEncoder.setVertexBuffer(0, verticesBuffer);\n      passEncoder.setBindGroup(0, uniformBindGroup);\n      passEncoder.draw(6, 1, 0, 0);\n      passEncoder.endPass();\n      device.defaultQueue.submit([commandEncoder.finish()]);\n    });\n  }\n}\n\nexport const glslShaders = {\n  vertex: `#version 450\nlayout(location = 0) in vec3 position;\nlayout(location = 1) in vec2 uv;\n\nlayout(location = 0) out vec2 fragUV;\n\nvoid main() {\n  gl_Position = vec4(position, 1.0);\n  fragUV = uv;\n}\n`,\n\n  fragment: `#version 450\nlayout(set = 0, binding = 0) uniform sampler mySampler;\nlayout(set = 0, binding = 1) uniform texture2D myTexture;\n\nlayout(location = 0) in vec2 fragUV;\nlayout(location = 0) out vec4 outColor;\n\nvoid main() {\n  outColor = texture(sampler2D(myTexture, mySampler), fragUV);\n}\n`,\n};\n\nexport const wgslShaders = {\n  vertex: `#version 450\n[[location(0)]] var<in> position : vec3<f32>;\n[[location(1)]] var<in> uv : vec2<f32>;\n\n[[location(0)]] var<out> fragUV : vec2<f32>;\n[[builtin(position)]] var<out> Position : vec4<f32>;\n\nvoid main() {\n  Position = vec4(position, 1.0);\n  fragUV = uv;\n}\n`,\n\n  fragment: `\n[[binding(0), set(0)]] var<uniform_constant> mySampler: sampler;\n[[binding(1), set(0)]] var<uniform_constant> myTexture: texture_sampled_2d<f32>;\n\n[[location(0)]] var<in> fragUV : vec2<f32>;\n[[location(0)]] var<out> outColor : vec4<f32>;\n\n[[stage(fragment)]]\nfn main() -> void {\n  outColor =  textureSample(myTexture, mySampler, fragUV);\n  return;\n}\n`,\n};\n"],"sourceRoot":""}